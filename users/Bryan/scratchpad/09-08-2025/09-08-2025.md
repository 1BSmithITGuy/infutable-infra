# 09-08-2025

# 09-07-2025

## Previous days (Talos deployment)

# 09-06-2025
 

--------## ***previous 3 days - Talos deployment:***--------
--------------------------------------------------------------------


## (09-04)

talos notes:

### **generate config:**

Make the config directory in the repo and run:
```bash
talosctl gen config "us103-talos01" "https://bsus103tal-k8m01.k8s.infutable.com:6443" --output-dir config --with-examples=false --with-docs=false --kubernetes-version 1.34.0
```

create yaml config files for control plane and 2 workers and merge those with the talos config:

```bash
talosctl machineconfig patch config/controlplane.yaml --patch @config/patches/control-plane.yaml --output config/controlplane-final.yaml

talosctl machineconfig patch config/worker.yaml --patch @config/patches/worker-01.yaml --output config/worker-01-final.yaml

talosctl machineconfig patch config/worker.yaml --patch @config/patches/worker-02.yaml --output config/worker-02-final.yaml
```

## (09-05)

---

#  Create VMs

### ISO download:  factory.talos.dev
- bare metal iso
- get the xen extension, and update the config:

```yaml
machine:
  systemExtensions:
    officialExtensions:
      - siderolabs/xen-guest-agent
```

## VM specs:
```
Control plane: 
- 4 GB RAM, 2 vCPU, 30GB disk
- bsus103tal-k8m01.k8s.infutable.com IP:  10.0.2.2/27

Workers (2):
- 4 GB RAM, 2 vCPU, 50GB disk
- bsus103tal-k8w01.k8s.infutable.com → 10.0.2.3/27
- bsus103tal-k8w02.k8s.infutable.com → 10.0.2.4/27
```

**Steps:**
1. Use "other install media" template

2. Boot from ISO on a VLAN with DHCP

3. Apply config to control plane node:
```bash
talosctl apply-config --insecure --nodes <IP_of_CP_node> --file controlplane-final.yaml
```
- switch to other network once IP changes

4. Copy the talosconfig file that was generated earlier to the file:  ***~/.talos/config***

5. Run the below command:
```bash
talosctl bootstrap --nodes 10.0.2.2 --endpoints 10.0.2.2
```

6.  
```bash
talosctl --nodes 10.0.2.2 --endpoints 10.0.2.2 config endpoint 10.0.2.2
```

7. 
```bash
talosctl kubeconfig --nodes 10.0.2.2 --force --merge
```

8. Install Cilium CNI (also see docs/cilium-talos-readme.md for other info, but this is what worked).
```bash
helm install cilium cilium/cilium \
  --namespace kube-system \
  --set ipam.mode=kubernetes \
  --set kubeProxyReplacement=true \
  --set securityContext.capabilities.ciliumAgent="{CHOWN,KILL,NET_ADMIN,NET_RAW,IPC_LOCK,SYS_ADMIN,SYS_RESOURCE,DAC_OVERRIDE,FOWNER,SETGID,SETUID}" \
  --set securityContext.capabilities.cleanCiliumState="{NET_ADMIN,SYS_ADMIN,SYS_RESOURCE}" \
  --set cgroup.autoMount.enabled=false \
  --set cgroup.hostRoot=/sys/fs/cgroup \
  --set k8sServiceHost=localhost \
  --set k8sServicePort=7445
  ```


9. Boot from ISO in DHCP VLAN and apply config to workers:
**NOTE:**  Like the CP node, switch to the correct VLAN once IP changes in console.
```bash
# worker 1:
talosctl apply-config --insecure --nodes <WORKER1_IP> --file worker-01-final.yaml

# worker 2:
talosctl apply-config --insecure --nodes <WORKER2_IP> --file worker-02-final.yaml
```






Replicas?  helm upgrade cilium cilium/cilium -n kube-system --set operator.replicas=2


***NEXT:***
    
```
- uncordon nodes
- replicate nodes as is.
- What should I deploy through argo or rancher below?

- kubeproxy replacement - true    ?  With cilium.  Do I want this?  do I need this?
- metallb, should I do rancher first, deploy through there?  
- setup pod backups on kubeadm and k3s cluster (valero?  veeam? maybe both, veeam for talos?)
        - maybe setup NFS, static IPs for truenas, and backup repo for XO backups with nightly talos backups?
- migrate apps
- setup XO backups/repo
- merge with main in repo
```

--------## ***09-06-2025 - Talos deployment:***--------
--------------------------------------------------------------------

**Cilium kube proxy replacement**

```bash
helm upgrade cilium cilium/cilium -n kube-system --set kubeProxyReplacement=true
```
***snapshot***

**troubleshooting**

Fixed Cilium, updated above process:
```bash
helm uninstall cilium -n kube-system

helm install cilium cilium/cilium \
  --namespace kube-system \
  --set ipam.mode=kubernetes \
  --set kubeProxyReplacement=true \
  --set securityContext.capabilities.ciliumAgent="{CHOWN,KILL,NET_ADMIN,NET_RAW,IPC_LOCK,SYS_ADMIN,SYS_RESOURCE,DAC_OVERRIDE,FOWNER,SETGID,SETUID}" \
  --set securityContext.capabilities.cleanCiliumState="{NET_ADMIN,SYS_ADMIN,SYS_RESOURCE}" \
  --set cgroup.autoMount.enabled=false \
  --set cgroup.hostRoot=/sys/fs/cgroup \
  --set k8sServiceHost=localhost \
  --set k8sServicePort=7445


# Since Cilium is running with `kubeProxyReplacement=true`, kube-proxy is redundant:

kubectl patch daemonset kube-proxy -n kube-system -p '{"spec":{"template":{"spec":{"nodeSelector":{"non-existing-node": "true"}}}}}'

```


--------## ***09-07-2025 - Talos deployment:***--------
--------------------------------------------------------------------


Install MetalLB:
```bash
helm repo add metallb https://metallb.github.io/metallb
helm repo update

helm install metallb metallb/metallb \
  --namespace metallb-system \
  --create-namespace \
  --version 0.15.2 \
  --set speaker.frr.enabled=false \
  --set speaker.tolerations[0].effect=NoSchedule \
  --set speaker.tolerations[0].operator=Exists
```

Configure MetalLB (./config/metallb/metal-lb-config.yaml):
```yaml
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: production-pool
  namespace: metallb-system
spec:
  addresses:
  - 10.0.2.7-10.0.2.13
  autoAssign: true
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: production-l2
  namespace: metallb-system
spec:
  ipAddressPools:
  - production-pool
#  Note:  I removed the below, supposedly metallb should auto-assign, and the interface I believe is enX0?
#  interfaces:
#  - eth0
  ```

troubleshoot metallb:
```bash
kubectl label namespace metallb-system pod-security.kubernetes.io/enforce=privileged --overwrite

kubectl label namespace metallb-system pod-security.kubernetes.io/audit=privileged --overwrite

kubectl label namespace metallb-system pod-security.kubernetes.io/warn=privileged --overwrite

kubectl rollout restart daemonset metallb-speaker -n metallb-system

helm upgrade metallb metallb/metallb \
  --namespace metallb-system \
  --version 0.15.2 \
  --set speaker.frr.enabled=false \
  --set speaker.tolerations[0].key="" \
  --set speaker.tolerations[0].operator=Exists \
  --set speaker.tolerations[0].effect=""
```


Install NGINX:

```bash
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

helm install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace \
  --version 4.12.0 \
  --set controller.service.type=LoadBalancer \
  --set controller.service.loadBalancerIP=10.0.2.7 \
  --set controller.ingressClassResource.default=true \
  --set controller.admissionWebhooks.enabled=false


```

--------## ***09-08-2025 - Talos deployment:***--------
--------------------------------------------------------------------

**Enable Hubble UI:**
```bash
helm upgrade cilium cilium/cilium \
  --namespace kube-system \
  --reuse-values \
  --set hubble.relay.enabled=true \
  --set hubble.ui.enabled=true \
  --set hubble.ui.service.type=ClusterIP

#  See ./talos/hubble-ui
k apply -f ingress.yaml

```
**ArgoCD:**
Created the directory /srv/secrets/clusters/us103-tal01, and copied files with secrets there. 


extract certs/keys and set permissions:

```bash
OUT=/srv/secrets/clusters/us103-talos01
talosctl --nodes 10.0.2.2 kubeconfig "$OUT/kubeconfig" --force
yq -r '.clusters[0].cluster."certificate-authority-data"' "$OUT/kubeconfig" | base64 -d > "$OUT/ca.crt"
yq -r '.users[0].user."client-certificate-data"'          "$OUT/kubeconfig" | base64 -d > "$OUT/admin.crt"
yq -r '.users[0].user."client-key-data"'                   "$OUT/kubeconfig" | base64 -d > "$OUT/admin.key"
chown root:gitadmins "$OUT"/{kubeconfig,ca.crt,admin.crt,admin.key}
chmod 0640 "$OUT"/{kubeconfig,ca.crt,admin.crt,admin.key}
```

Execute the file:
/srv/repos/infutable-infra/k8s/platform/talos/bin/register-argocd-cluster.sh



***NEXT:***

-  check if xen agent is running, troubleshoot that,

-  check what is after nginx in claude

-  rancher? 

- What should I deploy through argo or rancher below?

- setup pod backups on kubeadm and k3s cluster (valero?  veeam? maybe both, veeam for talos?)
- maybe setup NFS, static IPs for truenas, and backup repo for XO backups with nightly talos backups?
- migrate apps
- setup XO backups/repo
- merge with main in repo

- replicate nodes 
- finish documentaation above (fill out steps)

- shutdown process (cordon, etc)

***Documentation***
To do section:

future upgrades I would like to do:
- use BGP with MetalLB
- Migrate to all cilium instead of metal-lb

AI:  
- can you crunch the metallb troubleshooting part into a cleaner process for the readme?
- note that secrets are in:  All /srv/secrets/clusters/us103-talos01 (see below for structure)
 └── us103-talos01
│       ├── controlplane-final.yaml
│       ├── talosconfig
│       ├── worker-01-final.yaml
│       └── worker-02-final.yaml
- my alias is k for kubectl, any place where kubectl is can you use k in the documentation instead?  